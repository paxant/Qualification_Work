import os, random
import pickle as lpkl
import matplotlib.pyplot as plt
import numpy as np 
from sklearn.metrics import confusion_matrix
import pickle as cPickle
import seaborn as sns
from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import cross_val_score
import tensorflow as tf
import tensorflow.keras.models as models
from tensorflow.keras.datasets import cifar10
from tensorflow.keras import utils
from tensorflow.keras import metrics
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense, Reshape, Flatten,Activation,Dropout, Conv2D, MaxPooling2D, ZeroPadding2D, LSTM, BatchNormalization, GaussianNoise
from tensorflow.keras.losses import categorical_crossentropy
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import KFold
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import *
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import StratifiedKFold
import keras

def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Reds, labels=[]):
    #plt.cm.Reds - color shades to use, Reds, Blues, etc.
    # made the image bigger- 800x800
    my_dpi=96
    plt.figure(figsize=(800/my_dpi, 800/my_dpi), dpi=my_dpi)
    #key call- data, how to interpolate thefp vakues, color map
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    #adds a color legend to right hand side. Shows values for different shadings of blue.
    plt.colorbar()
    # create tickmarks with count = number of labels
    tick_marks = np.arange(len(labels))
    plt.xticks(tick_marks, labels, rotation=45)
    plt.yticks(tick_marks, labels)
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

dr = 0.1 # dropout rate (%)
model = Sequential()
model.add(Reshape((2, 128, 1), input_shape=(2, 128, 1)))
model.add(Conv2D(256, (1,3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))
model.add(layers.Dropout(dr))

model.add(Conv2D(256, (1,3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))
model.add(layers.Dropout(dr))

model.add(Conv2D(256, (1,3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))
model.add(layers.Dropout(dr))
model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dense(8, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

batch_size = 200

with open("/home/pov/.venv/intelintel/Qualification_Work/RDML/RML2016.10a_dict.pkl", 'rb') as f:
    Xd = cPickle.load(f, encoding="latin1") 
SNR = -20
for j in range(20):             
    del Xd[('AM-DSB', SNR)]
    del Xd[('AM-SSB', SNR)]
    del Xd[('WBFM', SNR)]                
    SNR = SNR + 2
    
snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])
X = []
lbl = []
for mod in mods:
    # mod is the label. mod = modulation scheme
    for snr in snrs:
        X.append(Xd[(mod,snr)])
        #snr = signal to noise ratio
        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))
X = np.vstack(X)

n_examples = X.shape[0]
# looks like taking half the samples for training

classes = mods


for i in range(10):
    i = 9
    file_history_path = '/home/pov/.venv/intelintel/Qualification_Work/RDML2016_A_K-flod/iter_' + str(i) + '/CNN_Model_10_fold_cross_vaild_history_' + str(i)
    file_model_path = '/home/pov/.venv/intelintel/Qualification_Work/RDML2016_A_K-flod/iter_' + str(i) + '/CNN_Model_10_fold_cross_vaild_' + str(i) + '.wts.h5' 
    file_test_data_path = '/home/pov/.venv/intelintel/Qualification_Work/RDML2016_A_K-flod/iter_' + str(i) + '/Test_Dataset_CNN_10_Fold_cross_valid_' + str(i)
    
    history_ = open(file_history_path, 'rb')
    history = lpkl.load(history_)                                    
    data_ = open(file_test_data_path, 'rb')
    data = lpkl.load(data_)
    model.load_weights(file_model_path)

    X_test = data[('X')]
    Y_test = data[('Y')]
    print(X_test)
    score = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)
    print (score)

    plt.figure()
    plt.title('Training performance')
    plt.plot(history.epoch, history.history['loss'], label='train loss+error')
    plt.plot(history.epoch, history.history['val_loss'], label='val_error')
    plt.legend()
    plt.show()
    #pass in X_test value and it predicts test_Y_hat
    test_Y_hat = model.predict(data[('X')], batch_size=batch_size, verbose = 1)
    #fill matrices with zeros
    conf = np.zeros([len(classes),len(classes)])
    #normalize c
    plt.show()
    #pass in X_test value and it predicts test_Y_hat
    test_Y_hat = model.predict(data[('X')], batch_size=batch_size, verbose = 1)
    #fill matrices with zeros
    conf = np.zeros([len(classes),len(classes)])
    #normalize confusion matrix
    confnorm = np.zeros([len(classes),len(classes)])
 
    #this puts all the data into an 11 x 11 matrix for plotting.
    for i in range(0,X_test.shape[0]):
        # j is first value in list
        j = list(Y_test[i,:]).index(1)
        #np.argmax gives the index of the max value in the array, assuming flattened into single vector
        k = int(np.argmax(test_Y_hat[i,:]))
        #why add 1 to each value??
        conf[j,k] = conf[j,k] + 1
 
#takes the data to plot and normalizes it
    for i in range(0,len(classes)):
        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])
    print (confnorm)
    print (classes)
    plot_confusion_matrix(confnorm, labels=classes)

# Plot confusion matrix
    acc = {}
    test_SNRs = []
    for i in range(len(X_test)):
        for snr in snrs:
            BOBL = np.vstack([Xd[(mod, snr)] for mod in mods])
            if np.any(np.all(X_test[i] == BOBL, axis=1)):
                print(i)
                test_SNRs.append(snr)
                break
            del BOBL

#this create a new confusion matrix for each SNR
    for snr in snrs:
        
    # extract classes @ SNR
    #changed map to list as part of upgrade from python2
        test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]
        test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]    
    # estimate classes
        test_Y_i_hat = model.predict(test_X_i, batch_size=batch_size, verbose = 1)
 
    #create 11x11 matrix full of zeroes
        conf = np.zeros([len(classes),len(classes)])
        confnorm = np.zeros([len(classes),len(classes)])
        for i in range(0,test_X_i.shape[0]):
            j = list(test_Y_i[i,:]).index(1)
            k = int(np.argmax(test_Y_i_hat[i,:]))
            conf[j,k] = conf[j,k] + 1
 
    #normalize 0 .. 1
        for i in range(0,len(classes)):
            confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])
        plot_confusion_matrix(confnorm, labels=classes, title="ConvNet Confusion Matrix (SNR=%d)"%(snr))
 
        cor = np.sum(np.diag(conf))
        ncor = np.sum(conf) - cor
        acc[snr] = 1.0*cor/(cor+ncor)


# Save results to a pickle file for plotting later
        print (acc)
# Plot accuracy curve
# map function produces generator in python3 which does not work with plt. Need a list.
# list(map(chr,[66,53,0,94]))
    plt.plot(snrs, list(map(lambda x: acc[x], snrs)))
    plt.xlabel("Signal to Noise Ratio")
    plt.ylabel("Classification Accuracy")
    plt.title("CNN2 Classification Accuracy on RadioML 2016.10 Alpha")
    import pandas

